{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "005_hw_mnist_fashion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:26.739189Z",
          "start_time": "2020-03-21T13:31:16.311066Z"
        },
        "id": "myRLFopGTGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# !pip install tensorflow-gpu==2.0.0-beta1\n",
        "# !pip install --upgrade keras\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:26.833938Z",
          "start_time": "2020-03-21T13:31:26.742181Z"
        },
        "id": "iIv8z1zPTGo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "# from keras_radam import RAdam    # try"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7mxgDg6TGpE",
        "colab_type": "text"
      },
      "source": [
        "# 1. 讀入 Fashion MNSIT 數據集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:26.854880Z",
          "start_time": "2020-03-21T13:31:26.838923Z"
        },
        "id": "zhYXYn9hTGpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:27.586922Z",
          "start_time": "2020-03-21T13:31:26.858871Z"
        },
        "id": "7TO-kMIETGpJ",
        "colab_type": "code",
        "outputId": "d749891d-6efe-4639-885a-e03b8b9b1b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T12:43:04.120678Z",
          "start_time": "2020-03-21T12:43:04.116686Z"
        },
        "id": "GjUpGt0OTGpP",
        "colab_type": "code",
        "outputId": "62a03bb0-327e-46cc-bb46-925cffcbf848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 看一下shape\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T12:52:06.063481Z",
          "start_time": "2020-03-21T12:52:06.051513Z"
        },
        "id": "6bCedLR7TGpU",
        "colab_type": "code",
        "outputId": "82224a98-6717-4b63-b672-97e52ac317f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xdDOU6ETGpY",
        "colab_type": "text"
      },
      "source": [
        "# 2. 欣賞數據集內容"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:27.597894Z",
          "start_time": "2020-03-21T13:31:27.592909Z"
        },
        "id": "2fc2xbkCTGpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:27.888118Z",
          "start_time": "2020-03-21T13:31:27.600886Z"
        },
        "id": "hdHGTj51TGpc",
        "colab_type": "code",
        "outputId": "589d32a4-c54e-4a60-8261-cc7054ec5a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "n = 1234\n",
        "print('這是', class_names[y_train[n]])\n",
        "plt.imshow(x_train[n], cmap='Greys');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "這是 Bag\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:28.155403Z",
          "start_time": "2020-03-21T13:31:27.891111Z"
        },
        "id": "DbpKWizqTGpg",
        "colab_type": "code",
        "outputId": "f0babae2-056d-44b3-dd61-55e57d6964d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "pick = np.random.choice(60000, 5, replace=False)    # 抽出不放回\n",
        "\n",
        "for i in range(5):\n",
        "    n = pick[i]\n",
        "    ax = plt.subplot(151+i)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(class_names[y_train[n]], fontsize=10)\n",
        "    plt.imshow(x_train[n], cmap='Greys')  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:28.167372Z",
          "start_time": "2020-03-21T13:31:28.159393Z"
        },
        "id": "y4LwsnmGTGpm",
        "colab_type": "code",
        "outputId": "d1e9d502-a6e3-4bbe-9ea8-a4b5db5f26c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pick"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   67, 34128, 51419, 59536, 49682])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hkdhJK6TGpp",
        "colab_type": "text"
      },
      "source": [
        "## 前處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-21T13:31:28.636119Z",
          "start_time": "2020-03-21T13:31:28.170364Z"
        },
        "id": "On3YzOfhTGpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "class_nums = len(class_names)\n",
        "\n",
        "\n",
        "# flatten and normalize\n",
        "x_train = x_train.reshape(60000, 784) / 255.\n",
        "x_test = x_test.reshape(10000, 784) / 255.\n",
        "\n",
        "x_train_original = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test_original = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "\n",
        "# one-hot y-data\n",
        "y_train = tf.keras.utils.to_categorical(y_train, class_nums)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, class_nums)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhYm-_LpTGpt",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "- CNN model\n",
        "    - baseline\n",
        "        - 卷積層3層\n",
        "    - activation一般都是用Relu, 用性質相近的leaky relu如何?\n",
        "        - relu\n",
        "        - leaky relu\n",
        "    - BatchNormalization要不要加，以及為什麼?加在哪?\n",
        "        - [BN在前還是activation在前](https://arxiv.org/pdf/1603.05027.pdf)\n",
        "            - 早期是BN在前，後面的論文研究BN在activation效果可能好一些。\n",
        "    - pooling要不要加，以及為什麼?\n",
        "        - MaxPooling\n",
        "            - MaxPooling 通常會在幾層 Convolution 後，⽤來降低 Feature Maps 的尺度以及強化特徵。\n",
        "        - AveragePooling\n",
        "    - optimizer要使用哪一個，以及為什麼?\n",
        "        - SGD\n",
        "        - Adam\n",
        "        - RMSP\n",
        "    - initializer要使用哪一種方式，以及為什麼?\n",
        "        - default\n",
        "        - others\n",
        "    - Flatten與GlobalAveragePooling差別在哪裡?要用哪一個?\n",
        "        - Flatten\n",
        "        - GlobalAveragePooling\n",
        "            - Global Average Pooling (GAP) 就是將每張Feature Map上的資訊以平\n",
        "均的⽅式壓為⼀個值\n",
        "                - 好處是什麼???\n",
        "    - loss function要用哪一個，以及為什麼?\n",
        "        - mse\n",
        "        - binary_crose_entropy\n",
        "    - early-stop\n",
        "    - maybe data augmentation or transfering learnging\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivy0nGTAiLSQ",
        "colab_type": "text"
      },
      "source": [
        "## Baseline CNN Model\n",
        "- #### 表現就不會太差了, 可以有一個直覺說, 淺層模型就足夠學到大部分的線條。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xJWT2BGA5IR",
        "colab_type": "code",
        "outputId": "0e20d10a-b6ba-4385-910c-abda3c1a41b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# baseline\n",
        "# 5s 10ms/step - loss: 0.0056 - accuracy: 0.9649 - val_loss: 0.0138 - val_accuracy: 0.9095\n",
        "# 明顯可以觀察到overfitting\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "# lr = 0.01\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding='same', \n",
        "                 input_shape=x_train_original.shape[1:],\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_original, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test_original, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 98,442\n",
            "Trainable params: 98,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0309 - accuracy: 0.7772 - val_loss: 0.0209 - val_accuracy: 0.8549\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0190 - accuracy: 0.8689 - val_loss: 0.0185 - val_accuracy: 0.8703\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0163 - accuracy: 0.8880 - val_loss: 0.0165 - val_accuracy: 0.8860\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0146 - accuracy: 0.9007 - val_loss: 0.0181 - val_accuracy: 0.8725\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0133 - accuracy: 0.9100 - val_loss: 0.0147 - val_accuracy: 0.8981\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0124 - accuracy: 0.9147 - val_loss: 0.0139 - val_accuracy: 0.9048\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0115 - accuracy: 0.9222 - val_loss: 0.0134 - val_accuracy: 0.9085\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0108 - accuracy: 0.9287 - val_loss: 0.0138 - val_accuracy: 0.9045\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0102 - accuracy: 0.9322 - val_loss: 0.0135 - val_accuracy: 0.9104\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0096 - accuracy: 0.9363 - val_loss: 0.0131 - val_accuracy: 0.9087\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0091 - accuracy: 0.9404 - val_loss: 0.0138 - val_accuracy: 0.9083\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0086 - accuracy: 0.9440 - val_loss: 0.0140 - val_accuracy: 0.9051\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0082 - accuracy: 0.9468 - val_loss: 0.0132 - val_accuracy: 0.9128\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0077 - accuracy: 0.9512 - val_loss: 0.0127 - val_accuracy: 0.9151\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0074 - accuracy: 0.9528 - val_loss: 0.0133 - val_accuracy: 0.9120\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0069 - accuracy: 0.9560 - val_loss: 0.0134 - val_accuracy: 0.9132\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0066 - accuracy: 0.9578 - val_loss: 0.0144 - val_accuracy: 0.9063\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0063 - accuracy: 0.9610 - val_loss: 0.0130 - val_accuracy: 0.9163\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0060 - accuracy: 0.9620 - val_loss: 0.0141 - val_accuracy: 0.9100\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0056 - accuracy: 0.9649 - val_loss: 0.0138 - val_accuracy: 0.9095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02c02aa358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9hSlWUrOjc_",
        "colab_type": "text"
      },
      "source": [
        "## 檢驗activation function效果\n",
        "- 效果兩者是差不多的，可能是因為此情形沒有dead neuron。\n",
        "    - 因此，維持原選擇relu，因為計算量還比較少。\n",
        "- [參考常用激勵函數以及如何選擇](https://blog.csdn.net/tyhj_sf/article/details/79932893)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIaSxK7bOJwu",
        "colab_type": "code",
        "outputId": "1285ba75-53cc-4bc2-e8ad-9fcc4a46ac67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding='same', \n",
        "                 input_shape=x_train_original.shape[1:],\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_original, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test_original, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 98,442\n",
            "Trainable params: 98,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.0283 - accuracy: 0.7970 - val_loss: 0.0202 - val_accuracy: 0.8623\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0180 - accuracy: 0.8766 - val_loss: 0.0191 - val_accuracy: 0.8630\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0155 - accuracy: 0.8943 - val_loss: 0.0162 - val_accuracy: 0.8891\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0141 - accuracy: 0.9048 - val_loss: 0.0153 - val_accuracy: 0.8964\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0131 - accuracy: 0.9118 - val_loss: 0.0153 - val_accuracy: 0.8948\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0122 - accuracy: 0.9181 - val_loss: 0.0145 - val_accuracy: 0.9001\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0114 - accuracy: 0.9231 - val_loss: 0.0140 - val_accuracy: 0.9053\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0108 - accuracy: 0.9280 - val_loss: 0.0137 - val_accuracy: 0.9081\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0101 - accuracy: 0.9330 - val_loss: 0.0144 - val_accuracy: 0.9016\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0096 - accuracy: 0.9368 - val_loss: 0.0135 - val_accuracy: 0.9071\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0092 - accuracy: 0.9394 - val_loss: 0.0133 - val_accuracy: 0.9087\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0087 - accuracy: 0.9437 - val_loss: 0.0131 - val_accuracy: 0.9109\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0083 - accuracy: 0.9465 - val_loss: 0.0133 - val_accuracy: 0.9109\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0079 - accuracy: 0.9488 - val_loss: 0.0143 - val_accuracy: 0.9049\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0076 - accuracy: 0.9519 - val_loss: 0.0133 - val_accuracy: 0.9120\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0073 - accuracy: 0.9542 - val_loss: 0.0135 - val_accuracy: 0.9120\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0070 - accuracy: 0.9554 - val_loss: 0.0144 - val_accuracy: 0.9059\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0066 - accuracy: 0.9577 - val_loss: 0.0141 - val_accuracy: 0.9084\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0064 - accuracy: 0.9601 - val_loss: 0.0146 - val_accuracy: 0.9052\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0062 - accuracy: 0.9614 - val_loss: 0.0151 - val_accuracy: 0.9050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02a0d28780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwoJN3PvtdwN",
        "colab_type": "text"
      },
      "source": [
        "## 測試initializer變換\n",
        "    - uniform\n",
        "    - defalut\n",
        "    - 結論: 兩者沒有太顯著的差異，當然這是很初步的測試，並沒有去調整其他lr等等來比較。\n",
        "        - 暫時維持原default的initializer\n",
        "        - 猜想: 在訓練參數大時, 理論上會有所差距。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-03-21T13:31:46.045Z"
        },
        "id": "2jwsJGhETGqB",
        "colab_type": "code",
        "outputId": "88bdc9fc-8726-4840-e5cc-10516d2656ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding='same', \n",
        "                 input_shape=x_train_original.shape[1:],\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu',\n",
        "                kernel_initializer='uniform'))\n",
        "model.add(Dense(10, activation='softmax',\n",
        "                kernel_initializer='uniform'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_original, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test_original, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 98,442\n",
            "Trainable params: 98,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0393 - accuracy: 0.7050 - val_loss: 0.0288 - val_accuracy: 0.7902\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0240 - accuracy: 0.8313 - val_loss: 0.0231 - val_accuracy: 0.8344\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0197 - accuracy: 0.8625 - val_loss: 0.0198 - val_accuracy: 0.8632\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0178 - accuracy: 0.8776 - val_loss: 0.0219 - val_accuracy: 0.8447\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0163 - accuracy: 0.8888 - val_loss: 0.0191 - val_accuracy: 0.8679\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0153 - accuracy: 0.8951 - val_loss: 0.0162 - val_accuracy: 0.8889\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0144 - accuracy: 0.9019 - val_loss: 0.0163 - val_accuracy: 0.8871\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0137 - accuracy: 0.9072 - val_loss: 0.0167 - val_accuracy: 0.8874\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0130 - accuracy: 0.9131 - val_loss: 0.0150 - val_accuracy: 0.8970\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0124 - accuracy: 0.9159 - val_loss: 0.0166 - val_accuracy: 0.8869\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0120 - accuracy: 0.9196 - val_loss: 0.0147 - val_accuracy: 0.8974\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0114 - accuracy: 0.9237 - val_loss: 0.0143 - val_accuracy: 0.9042\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0109 - accuracy: 0.9275 - val_loss: 0.0146 - val_accuracy: 0.9015\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0104 - accuracy: 0.9300 - val_loss: 0.0147 - val_accuracy: 0.9002\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0100 - accuracy: 0.9340 - val_loss: 0.0147 - val_accuracy: 0.9006\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0097 - accuracy: 0.9359 - val_loss: 0.0136 - val_accuracy: 0.9109\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0093 - accuracy: 0.9392 - val_loss: 0.0136 - val_accuracy: 0.9088\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0090 - accuracy: 0.9410 - val_loss: 0.0141 - val_accuracy: 0.9041\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0086 - accuracy: 0.9445 - val_loss: 0.0138 - val_accuracy: 0.9094\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0082 - accuracy: 0.9470 - val_loss: 0.0149 - val_accuracy: 0.9046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02c9c4ccc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQnvm5LfkYFX",
        "colab_type": "text"
      },
      "source": [
        "## 測試Pooling的效果\n",
        "- 有MaxPooling\n",
        "    - 參數減少非常多。\n",
        "    - 著重最顯著的特徵, 也比較符合一般的視覺直覺。\n",
        "- 沒有MaxPooling\n",
        "    - 參數多，訓練速度慢。\n",
        "    - 更為嚴重的overfitting, 但acc也是有所提升。\n",
        "- 有AveragePooling\n",
        "    - 參數同MaxPooling\n",
        "    - 相對於MaxPooling, 會柔和特徵。\n",
        "\n",
        "- 結論:\n",
        "    - 結果還是MaxPooling更好一些。\n",
        "        - 參數少, acc也是表現得比averagePooling更好一些。\n",
        "        - 但，這只是在\"全部\"都放相同的狀況下, 如果根據更深的CNN model\n",
        "            去做適當的放置, 我認為可能會表現得比單純全部都一樣好。\n",
        "            - 這些測試還沒有做, work有點太多QQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6SfGf3ktco",
        "colab_type": "code",
        "outputId": "bfefeb13-5299-4700-bd3a-8bb39d9fd9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding='same', \n",
        "                 input_shape=x_train_original.shape[1:],\n",
        "                 activation='relu'))\n",
        "# model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "# model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "# model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_original, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test_original, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 28, 28, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 6,447,242\n",
            "Trainable params: 6,447,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0209 - accuracy: 0.8539 - val_loss: 0.0150 - val_accuracy: 0.8960\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0121 - accuracy: 0.9177 - val_loss: 0.0133 - val_accuracy: 0.9089\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0089 - accuracy: 0.9408 - val_loss: 0.0122 - val_accuracy: 0.9174\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0065 - accuracy: 0.9574 - val_loss: 0.0130 - val_accuracy: 0.9150\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0047 - accuracy: 0.9701 - val_loss: 0.0126 - val_accuracy: 0.9186\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0034 - accuracy: 0.9787 - val_loss: 0.0124 - val_accuracy: 0.9221\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0026 - accuracy: 0.9845 - val_loss: 0.0122 - val_accuracy: 0.9217\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0020 - accuracy: 0.9883 - val_loss: 0.0124 - val_accuracy: 0.9244\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0017 - accuracy: 0.9905 - val_loss: 0.0134 - val_accuracy: 0.9218\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0014 - accuracy: 0.9919 - val_loss: 0.0133 - val_accuracy: 0.9214\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0013 - accuracy: 0.9928 - val_loss: 0.0139 - val_accuracy: 0.9182\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0012 - accuracy: 0.9934 - val_loss: 0.0136 - val_accuracy: 0.9217\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0011 - accuracy: 0.9940 - val_loss: 0.0138 - val_accuracy: 0.9216\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0010 - accuracy: 0.9943 - val_loss: 0.0134 - val_accuracy: 0.9244\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 9.7977e-04 - accuracy: 0.9947 - val_loss: 0.0146 - val_accuracy: 0.9175\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 9.4095e-04 - accuracy: 0.9947 - val_loss: 0.0139 - val_accuracy: 0.9214\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 9.0132e-04 - accuracy: 0.9951 - val_loss: 0.0146 - val_accuracy: 0.9173\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 8.8251e-04 - accuracy: 0.9951 - val_loss: 0.0153 - val_accuracy: 0.9166\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 8.6803e-04 - accuracy: 0.9952 - val_loss: 0.0142 - val_accuracy: 0.9200\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 8.4653e-04 - accuracy: 0.9953 - val_loss: 0.0141 - val_accuracy: 0.9226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02a128aa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvY5y2quo0RK",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer測試\n",
        "- RMSprop\n",
        "- Adam\n",
        "- SGD\n",
        "- 結論\n",
        "    - 這邊就不列出測試, 但幾乎就是Adam表現最好, 參數都是default\n",
        "    - 有參考許多文章, 幾乎Adam的穩定度都是大家所推崇。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtLEDkRXpgZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 20\n",
        "# lr = 0.01\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding='same', \n",
        "                 input_shape=x_train_original.shape[1:],\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_original, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test_original, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJZxdW0fqgXV",
        "colab_type": "text"
      },
      "source": [
        "## Flatten vs GlobalAveragePooling\n",
        "- Flatten\n",
        "- GlobalAveragePooling\n",
        "    - 參數少，會有特徵壓縮效果。\n",
        "    - 效果比起Flatten, overfitting情況較小, 但acc也下降了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCz7ciQyqpR2",
        "colab_type": "code",
        "outputId": "09b84085-9e0e-4ce5-bf33-2359857982d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# GlobalAveragePooling\n",
        "# 參數少很多, 但可想而知會失去一些特徵\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding='same', \n",
        "                 input_shape=x_train_original.shape[1:],\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_original, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test_original, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 32,906\n",
            "Trainable params: 32,906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0479 - accuracy: 0.6305 - val_loss: 0.0363 - val_accuracy: 0.7249\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0317 - accuracy: 0.7695 - val_loss: 0.0298 - val_accuracy: 0.7747\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0262 - accuracy: 0.8148 - val_loss: 0.0294 - val_accuracy: 0.7812\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0228 - accuracy: 0.8401 - val_loss: 0.0219 - val_accuracy: 0.8476\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0208 - accuracy: 0.8557 - val_loss: 0.0210 - val_accuracy: 0.8551\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0193 - accuracy: 0.8664 - val_loss: 0.0192 - val_accuracy: 0.8658\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0183 - accuracy: 0.8746 - val_loss: 0.0187 - val_accuracy: 0.8700\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0174 - accuracy: 0.8793 - val_loss: 0.0183 - val_accuracy: 0.8737\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0166 - accuracy: 0.8852 - val_loss: 0.0216 - val_accuracy: 0.8495\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0161 - accuracy: 0.8896 - val_loss: 0.0175 - val_accuracy: 0.8822\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0155 - accuracy: 0.8935 - val_loss: 0.0197 - val_accuracy: 0.8655\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0150 - accuracy: 0.8978 - val_loss: 0.0172 - val_accuracy: 0.8830\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0145 - accuracy: 0.9011 - val_loss: 0.0169 - val_accuracy: 0.8863\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0141 - accuracy: 0.9038 - val_loss: 0.0161 - val_accuracy: 0.8919\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0138 - accuracy: 0.9050 - val_loss: 0.0153 - val_accuracy: 0.8973\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0134 - accuracy: 0.9086 - val_loss: 0.0151 - val_accuracy: 0.8982\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0132 - accuracy: 0.9104 - val_loss: 0.0151 - val_accuracy: 0.8992\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0128 - accuracy: 0.9136 - val_loss: 0.0165 - val_accuracy: 0.8895\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0125 - accuracy: 0.9150 - val_loss: 0.0152 - val_accuracy: 0.8969\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0122 - accuracy: 0.9172 - val_loss: 0.0154 - val_accuracy: 0.8936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f029d1b0a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmX3m6UirYVV",
        "colab_type": "text"
      },
      "source": [
        "## 深度加深 + Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nDOxKoCTGqE",
        "colab_type": "code",
        "outputId": "24f37c75-3fa8-46e9-e597-b15cf69d8a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 超參數\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding='same',\n",
        "                 input_shape=x_test_original.shape[1:]))   # (60000, 28, 28, 1)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_original, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test_original, y_test),\n",
        "                    steps_per_epoch=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 26, 26, 32)        4640      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 508,170\n",
            "Trainable params: 508,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0305 - accuracy: 0.7826 - val_loss: 0.0217 - val_accuracy: 0.8465\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0195 - accuracy: 0.8653 - val_loss: 0.0168 - val_accuracy: 0.8802\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0166 - accuracy: 0.8874 - val_loss: 0.0146 - val_accuracy: 0.8972\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0149 - accuracy: 0.8995 - val_loss: 0.0133 - val_accuracy: 0.9090\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0140 - accuracy: 0.9054 - val_loss: 0.0133 - val_accuracy: 0.9078\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0131 - accuracy: 0.9115 - val_loss: 0.0136 - val_accuracy: 0.9057\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0125 - accuracy: 0.9164 - val_loss: 0.0118 - val_accuracy: 0.9188\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0120 - accuracy: 0.9187 - val_loss: 0.0118 - val_accuracy: 0.9189\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0116 - accuracy: 0.9222 - val_loss: 0.0120 - val_accuracy: 0.9172\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0113 - accuracy: 0.9247 - val_loss: 0.0113 - val_accuracy: 0.9248\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0109 - accuracy: 0.9275 - val_loss: 0.0114 - val_accuracy: 0.9232\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0105 - accuracy: 0.9300 - val_loss: 0.0118 - val_accuracy: 0.9232\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0103 - accuracy: 0.9319 - val_loss: 0.0115 - val_accuracy: 0.9224\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0102 - accuracy: 0.9321 - val_loss: 0.0115 - val_accuracy: 0.9240\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0100 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.9252\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0097 - accuracy: 0.9357 - val_loss: 0.0112 - val_accuracy: 0.9232\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0097 - accuracy: 0.9363 - val_loss: 0.0114 - val_accuracy: 0.9252\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0096 - accuracy: 0.9370 - val_loss: 0.0112 - val_accuracy: 0.9275\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0096 - accuracy: 0.9366 - val_loss: 0.0122 - val_accuracy: 0.9196\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0093 - accuracy: 0.9391 - val_loss: 0.0111 - val_accuracy: 0.9272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsQfk7gjCK0i",
        "colab_type": "code",
        "outputId": "02665df3-db1e-41e8-b91b-38ee8e64d7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 超參數\n",
        "# 沒有BN: 5s 80us/sample - loss: 0.0038 - accuracy: 0.9765 - val_loss: 0.0117 - val_accuracy: 0.9276\n",
        "# 有BN: 7s 120us/sample - loss: 0.0040 - accuracy: 0.9747 - val_loss: 0.0110 - val_accuracy: 0.9317\n",
        "# 有BN+Dense(1024): 8s 129us/sample - loss: 0.0047 - accuracy: 0.9709 - val_loss: 0.0113 - val_accuracy: 0.9329\n",
        "# BN+512+32: 7s 113us/sample - loss: 0.0044 - accuracy: 0.9722 - val_loss: 0.0110 - val_accuracy: 0.9309\n",
        "# 多了1x1 CNN: 8s 131us/sample - loss: 0.0041 - accuracy: 0.9740 - val_loss: 0.0118 - val_accuracy: 0.9277\n",
        "# 比原始還少一層 earlystop在16 : 6s 98us/sample - loss: 0.0062 - accuracy: 0.9594 - val_loss: 0.0124 - val_accuracy: 0.9210\n",
        "\n",
        "# lr=0.01, 超爛: 7s 123us/sample - loss: 0.0249 - accuracy: 0.8738 - val_loss: 0.0254 - val_accuracy: 0.8718\n",
        "# lr=0.002, 8s 133us/sample - loss: 0.0051 - accuracy: 0.9683 - val_loss: 0.0109 - val_accuracy: 0.9321\n",
        "# default還比較好= =\n",
        "\n",
        "# MaxPooling x3, 原本只有一個: 6s 106us/sample - loss: 0.0152 - accuracy: 0.8974 - val_loss: 0.0158 - val_accuracy: 0.8908\n",
        "\n",
        "# 原32-32-64\n",
        "# 32-64-128: 10s 159us/sample - loss: 0.0039 - accuracy: 0.9758 - val_loss: 0.0121 - val_accuracy: 0.9253\n",
        "# 16-32-64: 7s 120us/sample - loss: 0.0038 - accuracy: 0.9762 - val_loss: 0.0108 - val_accuracy: 0.9322\n",
        "# 64-128-256: overfitting : 15s 246us/sample - loss: 0.0025 - accuracy: 0.9850 - val_loss: 0.0108 - val_accuracy: 0.9313\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), padding='same',               \n",
        "                 input_shape=x_test_original.shape[1:]))   # (60000, 28, 28, 1)  # 原filter=32\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
        "model.add(Conv2D(128, (3, 3)))                  #\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))     # 修改, 原64\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))      # 修改\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "# callback\n",
        "earlystop = EarlyStopping(monitor=\"val_accuracy\", \n",
        "                          patience=5, \n",
        "                          verbose=1\n",
        "                          )\n",
        "\n",
        "\n",
        "model.compile(loss=binary_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "history = model.fit(x_train_original, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test_original, y_test),\n",
        "                    steps_per_epoch=None,\n",
        "                    callbacks=[earlystop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 512)               4719104   \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 5,097,738\n",
            "Trainable params: 5,095,818\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0748 - accuracy: 0.8536 - val_loss: 0.0964 - val_accuracy: 0.7953\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0482 - accuracy: 0.9038 - val_loss: 0.0480 - val_accuracy: 0.9033\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0417 - accuracy: 0.9165 - val_loss: 0.0502 - val_accuracy: 0.8985\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0370 - accuracy: 0.9257 - val_loss: 0.0498 - val_accuracy: 0.9034\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0334 - accuracy: 0.9338 - val_loss: 0.0422 - val_accuracy: 0.9163\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0304 - accuracy: 0.9390 - val_loss: 0.0394 - val_accuracy: 0.9244\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0280 - accuracy: 0.9442 - val_loss: 0.0395 - val_accuracy: 0.9248\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0264 - accuracy: 0.9476 - val_loss: 0.0402 - val_accuracy: 0.9258\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0231 - accuracy: 0.9545 - val_loss: 0.0459 - val_accuracy: 0.9205\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0209 - accuracy: 0.9583 - val_loss: 0.0428 - val_accuracy: 0.9222\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0203 - accuracy: 0.9605 - val_loss: 0.0482 - val_accuracy: 0.9168\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0178 - accuracy: 0.9655 - val_loss: 0.0701 - val_accuracy: 0.8822\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0163 - accuracy: 0.9685 - val_loss: 0.0423 - val_accuracy: 0.9269\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0147 - accuracy: 0.9716 - val_loss: 0.0508 - val_accuracy: 0.9179\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0138 - accuracy: 0.9735 - val_loss: 0.0583 - val_accuracy: 0.9133\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0126 - accuracy: 0.9761 - val_loss: 0.0446 - val_accuracy: 0.9284\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0117 - accuracy: 0.9779 - val_loss: 0.0523 - val_accuracy: 0.9239\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0116 - accuracy: 0.9774 - val_loss: 0.0486 - val_accuracy: 0.9238\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0100 - accuracy: 0.9812 - val_loss: 0.0475 - val_accuracy: 0.9280\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0098 - accuracy: 0.9817 - val_loss: 0.0515 - val_accuracy: 0.9280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j04QiL8StI5g",
        "colab_type": "code",
        "outputId": "4e458b14-a383-4253-e37d-29440970c271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), padding='same',               \n",
        "                 input_shape=x_test_original.shape[1:]))  \n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
        "model.add(Conv2D(128, (3, 3)))                  \n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))  \n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))      # 修改\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "# callback\n",
        "earlystop = EarlyStopping(monitor=\"val_accuracy\", \n",
        "                          patience=5, \n",
        "                          verbose=1\n",
        "                          )\n",
        "\n",
        "\n",
        "model.compile(loss=binary_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "history = model.fit(x_train_original, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test_original, y_test),\n",
        "                    steps_per_epoch=None,\n",
        "                    callbacks=[earlystop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_38 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 256)               2359552   \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,734,602\n",
            "Trainable params: 2,733,194\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0754 - accuracy: 0.8515 - val_loss: 0.1248 - val_accuracy: 0.7476\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0498 - accuracy: 0.9003 - val_loss: 0.0550 - val_accuracy: 0.8905\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0420 - accuracy: 0.9167 - val_loss: 0.0468 - val_accuracy: 0.9028\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0377 - accuracy: 0.9252 - val_loss: 0.0486 - val_accuracy: 0.9044\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0343 - accuracy: 0.9315 - val_loss: 0.0759 - val_accuracy: 0.8728\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0312 - accuracy: 0.9385 - val_loss: 0.0387 - val_accuracy: 0.9220\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0288 - accuracy: 0.9429 - val_loss: 0.0376 - val_accuracy: 0.9240\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0261 - accuracy: 0.9494 - val_loss: 0.0401 - val_accuracy: 0.9233\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0241 - accuracy: 0.9528 - val_loss: 0.0416 - val_accuracy: 0.9208\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0227 - accuracy: 0.9552 - val_loss: 0.0421 - val_accuracy: 0.9208\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0210 - accuracy: 0.9591 - val_loss: 0.0475 - val_accuracy: 0.9129\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0188 - accuracy: 0.9629 - val_loss: 0.0417 - val_accuracy: 0.9248\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0172 - accuracy: 0.9669 - val_loss: 0.0450 - val_accuracy: 0.9206\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0159 - accuracy: 0.9693 - val_loss: 0.0529 - val_accuracy: 0.9091\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0142 - accuracy: 0.9725 - val_loss: 0.0588 - val_accuracy: 0.9124\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0137 - accuracy: 0.9733 - val_loss: 0.0518 - val_accuracy: 0.9204\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0128 - accuracy: 0.9763 - val_loss: 0.0425 - val_accuracy: 0.9279\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0119 - accuracy: 0.9773 - val_loss: 0.0469 - val_accuracy: 0.9259\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0105 - accuracy: 0.9807 - val_loss: 0.0494 - val_accuracy: 0.9240\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0101 - accuracy: 0.9806 - val_loss: 0.0480 - val_accuracy: 0.9271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmMULHxduu2l",
        "colab_type": "text"
      },
      "source": [
        "## 結論\n",
        "- 加深acc會提高，但訓練速度也會減慢許多，在目前計算資源有限下, 我沒有繼續加深測試。\n",
        "- Adam優化器表現上還是比較優秀的，但lr我並沒有調整，這也是可以測試的項目之一。\n",
        "- MaxPooling2D表現較好, 但實際真實意義需要去看paper才能完整了解, 暫時沒有。\n",
        "- 理論上, 專為二元分類的損失函數表現會比較好, 但測試結果並沒有顯著差異。\n",
        "- 其餘測試結果如上次全連結差不多。\n",
        "- 我就沒有去測試一些RESNET等經典模型, 之後可以考慮用經典模型去測試。\n",
        "    - 如1x1的特徵汲取等等。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-prP5lcvoAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
